INFO: COMMAND: train.py --save-dir /Users/xiazeyu/nlu_cw2/results/Q6 --log-file /Users/xiazeyu/nlu_cw2/results/Q6/log.out --translate-log-file /Users/xiazeyu/nlu_cw2/results/Q6/translate.out --data /Users/xiazeyu/nlu_cw2/europarl_prepared --arch transformer
INFO: Arguments: {'data': '/Users/xiazeyu/nlu_cw2/europarl_prepared', 'source_lang': 'de', 'target_lang': 'en', 'max_tokens': None, 'batch_size': 10, 'train_on_tiny': False, 'arch': 'transformer', 'max_epoch': 100, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 10, 'log_file': '/Users/xiazeyu/nlu_cw2/results/Q6/log.out', 'translate_log_file': '/Users/xiazeyu/nlu_cw2/results/Q6/translate.out', 'save_dir': '/Users/xiazeyu/nlu_cw2/results/Q6', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 128, 'encoder_ffn_embed_dim': 512, 'encoder_layers': 2, 'encoder_attention_heads': 2, 'decoder_embed_dim': 128, 'decoder_ffn_embed_dim': 512, 'decoder_layers': 2, 'decoder_attention_heads': 2, 'dropout': 0.1, 'attention_dropout': 0.2, 'activation_dropout': 0.1, 'no_scale_embedding': False, 'device_id': 0}
INFO: Loaded a source dictionary (de) with 5047 words
INFO: Loaded a target dictionary (en) with 4420 words
INFO: Built a model with 2707652 parameters
INFO: Loaded checkpoint /Users/xiazeyu/nlu_cw2/results/Q6/checkpoint_last.pt
