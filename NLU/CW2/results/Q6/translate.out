[2021-03-09 16:44:45] COMMAND: translate.py --checkpoint-path /Users/xiazeyu/nlu_cw2/results/Q6/checkpoint_best.pt --output /Users/xiazeyu/nlu_cw2/results/Q6/model_translations.txt
[2021-03-09 16:44:45] Arguments: {'cuda': False, 'seed': 42, 'data': '/Users/xiazeyu/nlu_cw2/europarl_prepared', 'checkpoint_path': '/Users/xiazeyu/nlu_cw2/results/Q6/checkpoint_best.pt', 'batch_size': 10, 'output': '/Users/xiazeyu/nlu_cw2/results/Q6/model_translations.txt', 'max_len': 25, 'source_lang': 'de', 'target_lang': 'en', 'max_tokens': None, 'train_on_tiny': False, 'arch': 'transformer', 'max_epoch': 100, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 10, 'log_file': '/Users/xiazeyu/nlu_cw2/results/Q6/log.out', 'translate_log_file': '/Users/xiazeyu/nlu_cw2/results/Q6/translate.out', 'save_dir': '/Users/xiazeyu/nlu_cw2/results/Q6', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 128, 'encoder_ffn_embed_dim': 512, 'encoder_layers': 2, 'encoder_attention_heads': 2, 'decoder_embed_dim': 128, 'decoder_ffn_embed_dim': 512, 'decoder_layers': 2, 'decoder_attention_heads': 2, 'dropout': 0.1, 'attention_dropout': 0.2, 'activation_dropout': 0.1, 'no_scale_embedding': False, 'device_id': 0, 'max_src_positions': 512, 'max_tgt_positions': 512}
[2021-03-09 16:44:45] Loaded a source dictionary (de) with 5047 words
[2021-03-09 16:44:45] Loaded a target dictionary (en) with 4420 words
[2021-03-09 16:44:45] Loaded a model from checkpoint /Users/xiazeyu/nlu_cw2/results/Q6/checkpoint_best.pt
